{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "from typing import NoReturn\n",
    "from tqdm import tqdm\n",
    "\n",
    "from arguments import DataTrainingArguments, ModelArguments\n",
    "from datasets import DatasetDict, load_from_disk, load_metric, load_dataset\n",
    "from trainer_qa import QuestionAnsweringTrainer\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    "    EarlyStoppingCallback,\n",
    ")\n",
    "from utils_qa import check_no_error, postprocess_qa_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_DISABLED'] = 'false'\n",
    "os.environ['WANDB_PROJECT'] = 'level2-MRC'\n",
    "os.environ['WANDB_ENTITY'] = 'm2f'\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'JHW_JUPYTER_SERVER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 28\n",
    "deterministic = False\n",
    "\n",
    "random.seed(seed) # python random seed 고정\n",
    "np.random.seed(seed) # numpy random seed 고정\n",
    "torch.manual_seed(seed) # torch random seed 고정\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "if deterministic: # cudnn random seed 고정 - 고정 시 학습 속도가 느려질 수 있습니다. \n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "\ttorch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = ModelArguments()\n",
    "data_args = DataTrainingArguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./models/train_dataset2',\n",
    "\tseed=seed,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "\tlogging_dir='./logs',\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=1,\n",
    "\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=1e-5,\n",
    "    lr_scheduler_type='cosine',\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=100,\n",
    "\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model='eval_exact_match',\n",
    "    greater_is_better=True,\n",
    "\n",
    "    report_to='wandb',\n",
    "    run_name='JHW_28',\n",
    "\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -    %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "\n",
    "# verbosity 설정 : Transformers logger의 정보로 사용합니다 (on main process only)\n",
    "logger.info(\"Training/evaluation parameters %s\", training_args)\n",
    "\n",
    "# 모델을 초기화하기 전에 난수를 고정합니다.\n",
    "set_seed(training_args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_from_disk(data_args.dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets['train'] = datasets['train'].remove_columns(['document_id','__index_level_0__'])\n",
    "datasets['validation'] = datasets['validation'].remove_columns(['document_id','__index_level_0__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 70133\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['title', 'context', 'question', 'id', 'answers'],\n",
       "        num_rows: 240\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for korquad\n",
    "# korquad = load_dataset('parquet', data_files=['../data/train_aug.parquet'])\n",
    "# datasets['train'] = korquad['train']\n",
    "# datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## only use if you want to finetune korquad\n",
    "# datasets = load_dataset('squad_kor_v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Negative Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3952/3952 [49:15<00:00,  1.34it/s]  \n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "# Train 내의 Random Context 증강\n",
    "n_negative_samples = 2\n",
    "total_iteration = len(datasets['train'])\n",
    "\n",
    "for i in tqdm(range(total_iteration)):\n",
    "    temp_dict = datasets['train'][i]\n",
    "    temp_dict['answers'] = {'answer_start': [], 'text': []}\n",
    "    select_idx = np.random.choice([idx for idx in range(len(datasets['train'])) if idx != i], size=n_negative_samples, replace=False)\n",
    "    negative_datasets = datasets['train'].select(select_idx)\n",
    "    for n_context in negative_datasets['context']:\n",
    "        temp_dict['context'] = n_context\n",
    "        datasets['train'] = datasets['train'].add_item(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 11856/11856 [00:01<00:00, 10857.31 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 240/240 [00:00<00:00, 8979.86 examples/s] \n"
     ]
    }
   ],
   "source": [
    "datasets.save_to_disk('../data/negativetrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_from_disk('../data/negativetrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'context', 'question', 'id', 'answers'],\n",
       "        num_rows: 11856\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['title', 'context', 'question', 'id', 'answers'],\n",
       "        num_rows: 240\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model, Tokenizer, Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args.model_name_or_path = 'CurtisJeon/klue-roberta-large-korquad_v1_qa-finetuned_42'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 765/765 [00:00<00:00, 2.96MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 1.39k/1.39k [00:00<00:00, 548kB/s]\n",
      "vocab.txt: 100%|██████████| 248k/248k [00:00<00:00, 483kB/s]\n",
      "tokenizer.json: 100%|██████████| 752k/752k [00:00<00:00, 1.12MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 971/971 [00:00<00:00, 2.46MB/s]\n",
      "model.safetensors: 100%|██████████| 1.34G/1.34G [00:58<00:00, 23.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "    model_args.config_name\n",
    "    if model_args.config_name is not None\n",
    "    else model_args.model_name_or_path,\n",
    "    cache_dir='/data/ephemeral/huggingface'\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_args.tokenizer_name\n",
    "    if model_args.tokenizer_name is not None\n",
    "    else model_args.model_name_or_path,\n",
    "    # 'use_fast' argument를 True로 설정할 경우 rust로 구현된 tokenizer를 사용할 수 있습니다.\n",
    "    # False로 설정할 경우 python으로 구현된 tokenizer를 사용할 수 있으며,\n",
    "    # rust version이 비교적 속도가 빠릅니다.\n",
    "    use_fast=True,\n",
    "    cache_dir='/data/ephemeral/huggingface'\n",
    ")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n",
    "    config=config,\n",
    "    cache_dir='/data/ephemeral/huggingface'\n",
    ")\n",
    "\n",
    "## token_type_ids 를 쓰는지 안쓰는지\n",
    "use_token_type_ids = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:821: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "model.safetensors: 100%|██████████| 1.34G/1.34G [00:55<00:00, 24.0MB/s]\n",
      "README.md: 100%|██████████| 5.18k/5.18k [00:00<00:00, 9.13MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/CurtisJeon/klue-roberta-large-korquad_v1_qa-finetuned/commit/60fea41d546df062d8e98c20e2a66864d7e08558', commit_message='Upload tokenizer', commit_description='', oid='60fea41d546df062d8e98c20e2a66864d7e08558', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For Hub Upload\n",
    "MODEL_SAVE_REPO = 'klue-roberta-large-korquad_v1_qa-finetuned'\n",
    "API_KEY = ''\n",
    "\n",
    "# model.push_to_hub(\n",
    "#     MODEL_SAVE_REPO , \n",
    "#     use_temp_dir=True, \n",
    "#     use_auth_token=API_KEY\n",
    "# )\n",
    "\n",
    "# tokenizer.push_to_hub(\n",
    "#     MODEL_SAVE_REPO , \n",
    "#     use_temp_dir=True, \n",
    "#     use_auth_token=API_KEY\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRC-Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = datasets[\"train\"].column_names\n",
    "question_column_name = \"question\" if \"question\" in column_names else column_names[0]\n",
    "context_column_name = \"context\" if \"context\" in column_names else column_names[1]\n",
    "answer_column_name = \"answers\" if \"answers\" in column_names else column_names[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding에 대한 옵션을 설정합니다.\n",
    "# (question|context) 혹은 (context|question)로 세팅 가능합니다.\n",
    "pad_on_right = tokenizer.padding_side == \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오류가 있는지 확인합니다.\n",
    "last_checkpoint, max_seq_length = check_no_error(\n",
    "    data_args, training_args, datasets, tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Train preprocessing / 전처리를 진행합니다.\n",
    "def prepare_train_features(examples):\n",
    "    # truncation과 padding(length가 짧을때만)을 통해 toknization을 진행하며, stride를 이용하여 overflow를 유지합니다.\n",
    "    # 각 example들은 이전의 context와 조금씩 겹치게됩니다.\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[question_column_name if pad_on_right else context_column_name],\n",
    "        examples[context_column_name if pad_on_right else question_column_name],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_seq_length,\n",
    "        stride=data_args.doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        return_token_type_ids=use_token_type_ids, # roberta모델을 사용할 경우 False, bert를 사용할 경우 True로 표기해야합니다.\n",
    "        padding=\"max_length\" if data_args.pad_to_max_length else False,\n",
    "    )\n",
    "\n",
    "    # 길이가 긴 context가 등장할 경우 truncate를 진행해야하므로, 해당 데이터셋을 찾을 수 있도록 mapping 가능한 값이 필요합니다.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    # token의 캐릭터 단위 position를 찾을 수 있도록 offset mapping을 사용합니다.\n",
    "    # start_positions과 end_positions을 찾는데 도움을 줄 수 있습니다.\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "    # 데이터셋에 \"start position\", \"enc position\" label을 부여합니다.\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)  # cls index\n",
    "\n",
    "        # sequence id를 설정합니다 (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "        # 하나의 example이 여러개의 span을 가질 수 있습니다.\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples[answer_column_name][sample_index]\n",
    "\n",
    "        # answer가 없을 경우 cls_index를 answer로 설정합니다(== example에서 정답이 없는 경우 존재할 수 있음).\n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            # text에서 정답의 Start/end character index\n",
    "            start_char = answers[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "            # text에서 current span의 Start token index\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
    "                token_start_index += 1\n",
    "\n",
    "            # text에서 current span의 End token index\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
    "                token_end_index -= 1\n",
    "\n",
    "            # 정답이 span을 벗어났는지 확인합니다(정답이 없는 경우 CLS index로 label되어있음).\n",
    "            if not (\n",
    "                offsets[token_start_index][0] <= start_char\n",
    "                and offsets[token_end_index][1] >= end_char\n",
    "            ):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                # token_start_index 및 token_end_index를 answer의 끝으로 이동합니다.\n",
    "                # Note: answer가 마지막 단어인 경우 last offset을 따라갈 수 있습니다(edge case).\n",
    "                while (\n",
    "                    token_start_index < len(offsets)\n",
    "                    and offsets[token_start_index][0] <= start_char\n",
    "                ):\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_examples\n",
    "\n",
    "# Validation preprocessing\n",
    "def prepare_validation_features(examples):\n",
    "    # truncation과 padding(length가 짧을때만)을 통해 toknization을 진행하며, stride를 이용하여 overflow를 유지합니다.\n",
    "    # 각 example들은 이전의 context와 조금씩 겹치게됩니다.\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[question_column_name if pad_on_right else context_column_name],\n",
    "        examples[context_column_name if pad_on_right else question_column_name],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_seq_length,\n",
    "        stride=data_args.doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        return_token_type_ids=use_token_type_ids, # roberta모델을 사용할 경우 False, bert를 사용할 경우 True로 표기해야합니다.\n",
    "        padding=\"max_length\" if data_args.pad_to_max_length else False,\n",
    "    )\n",
    "\n",
    "    # 길이가 긴 context가 등장할 경우 truncate를 진행해야하므로, 해당 데이터셋을 찾을 수 있도록 mapping 가능한 값이 필요합니다.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    # evaluation을 위해, prediction을 context의 substring으로 변환해야합니다.\n",
    "    # corresponding example_id를 유지하고 offset mappings을 저장해야합니다.\n",
    "    tokenized_examples[\"example_id\"] = []\n",
    "\n",
    "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
    "        # sequence id를 설정합니다 (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        context_index = 1 if pad_on_right else 0\n",
    "\n",
    "        # 하나의 example이 여러개의 span을 가질 수 있습니다.\n",
    "        sample_index = sample_mapping[i]\n",
    "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
    "\n",
    "        # Set to None the offset_mapping을 None으로 설정해서 token position이 context의 일부인지 쉽게 판별 할 수 있습니다.\n",
    "        tokenized_examples[\"offset_mapping\"][i] = [\n",
    "            (o if sequence_ids[k] == context_index else None)\n",
    "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
    "        ]\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3952/3952 [00:05<00:00, 758.11 examples/s]\n",
      "Map: 100%|██████████| 240/240 [00:00<00:00, 548.35 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets[\"train\"]\n",
    "\n",
    "# dataset에서 train feature를 생성합니다.\n",
    "train_dataset = train_dataset.map(\n",
    "    prepare_train_features,\n",
    "    batched=True,\n",
    "    num_proc=data_args.preprocessing_num_workers,\n",
    "    remove_columns=column_names,\n",
    "    load_from_cache_file=not data_args.overwrite_cache,\n",
    ")\n",
    "\n",
    "eval_dataset = datasets[\"validation\"]\n",
    "\n",
    "# Validation Feature 생성\n",
    "eval_dataset = eval_dataset.map(\n",
    "    prepare_validation_features,\n",
    "    batched=True,\n",
    "    num_proc=data_args.preprocessing_num_workers,\n",
    "    remove_columns=column_names,\n",
    "    load_from_cache_file=not data_args.overwrite_cache,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer, pad_to_multiple_of=8 if training_args.fp16 else None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRC-Postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing:\n",
    "def post_processing_function(examples, features, predictions, training_args):\n",
    "    # Post-processing: start logits과 end logits을 original context의 정답과 match시킵니다.\n",
    "    predictions = postprocess_qa_predictions(\n",
    "        examples=examples,\n",
    "        features=features,\n",
    "        predictions=predictions,\n",
    "        max_answer_length=data_args.max_answer_length,\n",
    "        output_dir=training_args.output_dir,\n",
    "    )\n",
    "    # Metric을 구할 수 있도록 Format을 맞춰줍니다.\n",
    "    formatted_predictions = [\n",
    "        {\"id\": k, \"prediction_text\": v} for k, v in predictions.items()\n",
    "    ]\n",
    "    if training_args.do_predict:\n",
    "        return formatted_predictions\n",
    "\n",
    "    elif training_args.do_eval:\n",
    "        references = [\n",
    "            {\"id\": ex[\"id\"], \"answers\": ex[answer_column_name]}\n",
    "            for ex in datasets[\"validation\"]\n",
    "        ]\n",
    "        return EvalPrediction(\n",
    "            predictions=formatted_predictions, label_ids=references\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_972700/212718684.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"squad\")\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"squad\")\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    return metric.compute(predictions=p.predictions, references=p.label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find JHW_JUPYTER_SERVER.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgusdnr122997\u001b[0m (\u001b[33mm2af\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /data/ephemeral/home/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStoppingCallback(\n",
    "     early_stopping_patience=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/22/2024 07:52:07 - WARNING - accelerate.utils.other -    Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# Trainer 초기화\n",
    "trainer = QuestionAnsweringTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset if training_args.do_train else None,\n",
    "    eval_dataset=eval_dataset if training_args.do_eval else None,\n",
    "    eval_examples=datasets[\"validation\"] if training_args.do_eval else None,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    post_process_function=post_processing_function,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgusdnr122997\u001b[0m (\u001b[33mm2f\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/level2-mrc/code/wandb/run-20240222_074916-eynu2cpd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/m2f/level2-MRC/runs/eynu2cpd' target=\"_blank\">JHW_korquad_finetuned_2</a></strong> to <a href='https://wandb.ai/m2f/level2-MRC' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/m2f/level2-MRC' target=\"_blank\">https://wandb.ai/m2f/level2-MRC</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/m2f/level2-MRC/runs/eynu2cpd' target=\"_blank\">https://wandb.ai/m2f/level2-MRC/runs/eynu2cpd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='5430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  32/5430 00:38 < 1:54:57, 0.78 it/s, Epoch 0.06/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training\n",
    "if training_args.do_train:\n",
    "    if last_checkpoint is not None:\n",
    "        checkpoint = last_checkpoint\n",
    "    elif os.path.isdir(model_args.model_name_or_path):\n",
    "        checkpoint = model_args.model_name_or_path\n",
    "    else:\n",
    "        checkpoint = None\n",
    "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
    "    trainer.save_model()  # Saves the tokenizer too for easy upload\n",
    "\n",
    "    metrics = train_result.metrics\n",
    "    metrics[\"train_samples\"] = len(train_dataset)\n",
    "\n",
    "    trainer.log_metrics(\"train\", metrics)\n",
    "    trainer.save_metrics(\"train\", metrics)\n",
    "    trainer.save_state()\n",
    "\n",
    "    output_train_file = os.path.join(training_args.output_dir, \"train_results.txt\")\n",
    "\n",
    "    with open(output_train_file, \"w\") as writer:\n",
    "        logger.info(\"***** Train results *****\")\n",
    "        for key, value in sorted(train_result.metrics.items()):\n",
    "            logger.info(f\"  {key} = {value}\")\n",
    "            writer.write(f\"{key} = {value}\\n\")\n",
    "\n",
    "    # State 저장\n",
    "    trainer.state.save_to_json(\n",
    "        os.path.join(training_args.output_dir, \"trainer_state.json\")\n",
    "    )\n",
    "\n",
    "# Evaluation\n",
    "if training_args.do_eval:\n",
    "    logger.info(\"*** Evaluate ***\")\n",
    "    metrics = trainer.evaluate()\n",
    "\n",
    "    metrics[\"eval_samples\"] = len(eval_dataset)\n",
    "\n",
    "    trainer.log_metrics(\"eval\", metrics)\n",
    "    trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/exact_match</td><td>▁▃▆█▆▆▅█</td></tr><tr><td>eval/f1</td><td>▁▂▇█▆▅▆█</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>▁▂▃▅▆██████████████████████████████████▇</td></tr><tr><td>train/loss</td><td>▄█▇▅▃▅▆▆▆▆▄▂▂▇▄▄▄▂▇▆▅▂▄▂▃▃▃▅▃▃▁▅▁▄▂▂▆▃▃▃</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/exact_match</td><td>70.83333</td></tr><tr><td>eval/f1</td><td>80.93161</td></tr><tr><td>train/epoch</td><td>1.94</td></tr><tr><td>train/global_step</td><td>700</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.1296</td></tr><tr><td>train/total_flos</td><td>2.071736340364339e+16</td></tr><tr><td>train/train_loss</td><td>0.30219</td></tr><tr><td>train/train_runtime</td><td>1038.4126</td></tr><tr><td>train/train_samples_per_second</td><td>110.977</td></tr><tr><td>train/train_steps_per_second</td><td>3.467</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">JHW_korquad_finetuned_2</strong> at: <a href='https://wandb.ai/m2f/level2-MRC/runs/pylimvbn' target=\"_blank\">https://wandb.ai/m2f/level2-MRC/runs/pylimvbn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240221_132049-pylimvbn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, List, NoReturn, Tuple\n",
    "from datasets import (\n",
    "    Dataset,\n",
    "    DatasetDict,\n",
    "    Features,\n",
    "    Sequence,\n",
    "    Value,\n",
    "    load_from_disk,\n",
    "    load_metric,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = ModelArguments(\n",
    "    model_name_or_path='./models/train_dataset/',\n",
    ")\n",
    "data_args = DataTrainingArguments(\n",
    "    dataset_name='../data/test_dataset/',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./outputs/test_dataset3/',\n",
    "\tseed=seed,\n",
    "\n",
    "    do_train=True,\n",
    "    do_predict=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'id'],\n",
       "        num_rows: 600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_datasets = load_from_disk(data_args.dataset_name)\n",
    "test_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval (Sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if True\n",
    "data_args.eval_retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of unique contexts : 55963\n",
      "Embedding pickle load.\n"
     ]
    }
   ],
   "source": [
    "from retrieval import SparseRetrieval\n",
    "from bm25 import BM25\n",
    "\n",
    "# retriever = SparseRetrieval(\n",
    "#     tokenize_fn=tokenizer.tokenize, data_path=\"../data\", context_path=\"wiki_preprocessed.json\"\n",
    "# )\n",
    "passage_tokenizer = AutoTokenizer.from_pretrained('monologg/koelectra-base-v3-finetuned-korquad', cache_dir='/data/ephemeral/huggingface')\n",
    "\n",
    "retriever = BM25(\n",
    "    tokenize_fn=passage_tokenizer.tokenize, data_path=\"../data\", context_path=\"wiki_preprocessed_v2.json\"\n",
    ")\n",
    "retriever.get_sparse_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faiss: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [12:39<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[query exhaustive search] done in 762.739 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sparse retrieval: 100%|██████████| 600/600 [00:00<00:00, 10147.63it/s]\n"
     ]
    }
   ],
   "source": [
    "print('Faiss:', data_args.use_faiss)\n",
    "if data_args.use_faiss:\n",
    "    retriever.build_faiss(num_clusters=data_args.num_clusters)\n",
    "    df = retriever.retrieve_faiss(\n",
    "        test_datasets[\"validation\"], topk=data_args.top_k_retrieval\n",
    "    )\n",
    "else:\n",
    "    df = retriever.retrieve(test_datasets[\"validation\"], topk=data_args.top_k_retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>유령'은 어느 행성에서 지구로 왔는가?</td>\n",
       "      <td>mrc-1-000653</td>\n",
       "      <td>목성의 대기에서 보이는 줄무늬는 적도와 평행하면서 행성을 둘러싸는 대(zone)와 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>용병회사의 경기가 좋아진 것은 무엇이 끝난 이후부터인가?</td>\n",
       "      <td>mrc-1-001113</td>\n",
       "      <td>냉전 종식 이후 전 세계적으로 소규모의 끊임없는 국지 분쟁들이 생겨나고 강대국들의 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>돌푸스에게 불특정 기간동안 하원이 잠시 쉬는 것을 건의 받았던 인물은?</td>\n",
       "      <td>mrc-0-002191</td>\n",
       "      <td>1933년 3월, 투표 과정의 위법성에 대한 문제제기가 불거졌다. 당시 오스트리아 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>마오리언어와 영어, 뉴질랜드 수화를 공식 언어로 사용하는 나라는?</td>\n",
       "      <td>mrc-0-003951</td>\n",
       "      <td>유럽인들의 아메리카와 오세아니아 식민지화로 인해 아메리카와 오세아니아의 문화적, 민...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>디엔비엔푸 전투에서 보응우옌잡이 상대한 국가는?</td>\n",
       "      <td>mrc-1-001272</td>\n",
       "      <td>1926년 학생 시절 베트남청년혁명당에 가입했고 1930년에 학생 파업을 지지했다는...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  question            id  \\\n",
       "0                    유령'은 어느 행성에서 지구로 왔는가?  mrc-1-000653   \n",
       "1          용병회사의 경기가 좋아진 것은 무엇이 끝난 이후부터인가?  mrc-1-001113   \n",
       "2  돌푸스에게 불특정 기간동안 하원이 잠시 쉬는 것을 건의 받았던 인물은?  mrc-0-002191   \n",
       "3     마오리언어와 영어, 뉴질랜드 수화를 공식 언어로 사용하는 나라는?  mrc-0-003951   \n",
       "4               디엔비엔푸 전투에서 보응우옌잡이 상대한 국가는?  mrc-1-001272   \n",
       "\n",
       "                                             context  \n",
       "0  목성의 대기에서 보이는 줄무늬는 적도와 평행하면서 행성을 둘러싸는 대(zone)와 ...  \n",
       "1  냉전 종식 이후 전 세계적으로 소규모의 끊임없는 국지 분쟁들이 생겨나고 강대국들의 ...  \n",
       "2  1933년 3월, 투표 과정의 위법성에 대한 문제제기가 불거졌다. 당시 오스트리아 ...  \n",
       "3  유럽인들의 아메리카와 오세아니아 식민지화로 인해 아메리카와 오세아니아의 문화적, 민...  \n",
       "4  1926년 학생 시절 베트남청년혁명당에 가입했고 1930년에 학생 파업을 지지했다는...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/bm25_k25_v2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': Value(dtype='string', id=None),\n",
       " 'id': Value(dtype='string', id=None),\n",
       " 'question': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data 에 대해선 정답이 없으므로 id question context 로만 데이터셋이 구성됩니다.\n",
    "if training_args.do_predict:\n",
    "    f = Features(\n",
    "        {\n",
    "            \"context\": Value(dtype=\"string\", id=None),\n",
    "            \"id\": Value(dtype=\"string\", id=None),\n",
    "            \"question\": Value(dtype=\"string\", id=None),\n",
    "        }\n",
    "    )\n",
    "elif training_args.do_eval:\n",
    "    f = Features(\n",
    "        {\n",
    "            \"answers\": Sequence(\n",
    "                feature={\n",
    "                    \"text\": Value(dtype=\"string\", id=None),\n",
    "                    \"answer_start\": Value(dtype=\"int32\", id=None),\n",
    "                },\n",
    "                length=-1,\n",
    "                id=None,\n",
    "            ),\n",
    "            \"context\": Value(dtype=\"string\", id=None),\n",
    "            \"id\": Value(dtype=\"string\", id=None),\n",
    "            \"question\": Value(dtype=\"string\", id=None),\n",
    "        }\n",
    "    )\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['context', 'id', 'question'],\n",
       "        num_rows: 600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_datasets = DatasetDict({\"validation\": Dataset.from_pandas(df, features=f)})\n",
    "test_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval(DPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dpr import DenseRetrieval\n",
    "from transformers import TrainingArguments, AutoTokenizer\n",
    "from inference import *\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"dense_retrieval\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "train_dataset = datasets['train']\n",
    "cache_dir = '/data/ephemeral/huggingface'\n",
    "\n",
    "p_encoder_path = '/data/ephemeral/huggingface/p_encoder_bert'\n",
    "q_encoder_path = '/data/ephemeral/huggingface/q_encoder_bert'\n",
    "ep_tokenizer = AutoTokenizer.from_pretrained('klue/bert-base', cache_dir=cache_dir)\n",
    "p_encoder = BertEncoder.from_pretrained(p_encoder_path, cache_dir=cache_dir).to(args.device)\n",
    "q_encoder = BertEncoder.from_pretrained(q_encoder_path, cache_dir=cache_dir).to(args.device)\n",
    "\n",
    "retriever = DenseRetrieval(\n",
    "    args=args,\n",
    "    dataset=train_dataset,\n",
    "    num_neg=2,\n",
    "    tokenizer=ep_tokenizer,\n",
    "    p_encoder=p_encoder,\n",
    "    q_encoder=q_encoder,\n",
    "    do_train=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DenseRetrieval' object has no attribute 'do_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_train\u001b[49m:\n\u001b[1;32m      2\u001b[0m     retriever\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DenseRetrieval' object has no attribute 'do_train'"
     ]
    }
   ],
   "source": [
    "if retriever.do_train:\n",
    "    retriever.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding pickle load.\n"
     ]
    }
   ],
   "source": [
    "retriever.get_dense_embeddings('../data/dense.bin', corpus_path=\"../data/wiki_preprocessed_v2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:09<00:00, 60.70it/s]\n",
      "100%|██████████| 600/600 [00:02<00:00, 257.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[query exhaustive search] done in 12.616 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dense retrieval: 100%|██████████| 600/600 [00:03<00:00, 163.50it/s]\n"
     ]
    }
   ],
   "source": [
    "df = retriever.retrieve(test_datasets[\"validation\"], topk=data_args.top_k_retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Features(\n",
    "    {\n",
    "        \"context\": Value(dtype=\"string\", id=None),\n",
    "        \"id\": Value(dtype=\"string\", id=None),\n",
    "        \"question\": Value(dtype=\"string\", id=None),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datasets = DatasetDict({\"validation\": Dataset.from_pandas(df, features=f)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['context', 'id', 'question'],\n",
       "        num_rows: 600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval(BM25 + DPR)\n",
    "- ver2 : add SentTran Retrieval -> Remove (Low Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of unique contexts : 55963\n",
      "Embedding pickle load.\n",
      "Embedding pickle load.\n"
     ]
    }
   ],
   "source": [
    "from custom_retriever import CustomRetriever\n",
    "\n",
    "p_encoder_path = 'CurtisJeon/klue-bert-base-context'\n",
    "q_encoder_path = 'CurtisJeon/klue-bert-base-question'\n",
    "\n",
    "retriever = CustomRetriever(\n",
    "    p_encoder_path=p_encoder_path, q_encoder_path=q_encoder_path, weights=(0.5, 0.5) # (bm25, dpr)\n",
    ")\n",
    "# retriever.dpr_tokenizer = AutoTokenizer.from_pretrained('kykim/bert-kor-base', cache_dir='/data/ephemeral/huggingface')\n",
    "retriever.get_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 Result pickle load.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:11<00:00, 52.32it/s]\n",
      "100%|██████████| 600/600 [00:07<00:00, 79.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[query exhaustive search] done in 91.225 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sparse retrieval: 100%|██████████| 600/600 [00:00<00:00, 3458.59it/s]\n"
     ]
    }
   ],
   "source": [
    "df = retriever.retrieve(test_datasets[\"validation\"], topk=data_args.top_k_retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/bm25_dpr(5_5)_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>유령'은 어느 행성에서 지구로 왔는가?</td>\n",
       "      <td>mrc-1-000653</td>\n",
       "      <td>목성의 대기에서 보이는 줄무늬는 적도와 평행하면서 행성을 둘러싸는 대(zone)와 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>용병회사의 경기가 좋아진 것은 무엇이 끝난 이후부터인가?</td>\n",
       "      <td>mrc-1-001113</td>\n",
       "      <td>냉전 종식 이후 전 세계적으로 소규모의 끊임없는 국지 분쟁들이 생겨나고 강대국들의 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>돌푸스에게 불특정 기간동안 하원이 잠시 쉬는 것을 건의 받았던 인물은?</td>\n",
       "      <td>mrc-0-002191</td>\n",
       "      <td>1933년 3월, 투표 과정의 위법성에 대한 문제제기가 불거졌다. 당시 오스트리아 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>마오리언어와 영어, 뉴질랜드 수화를 공식 언어로 사용하는 나라는?</td>\n",
       "      <td>mrc-0-003951</td>\n",
       "      <td>유럽인들의 아메리카와 오세아니아 식민지화로 인해 아메리카와 오세아니아의 문화적, 민...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>디엔비엔푸 전투에서 보응우옌잡이 상대한 국가는?</td>\n",
       "      <td>mrc-1-001272</td>\n",
       "      <td>1926년 학생 시절 베트남청년혁명당에 가입했고 1930년에 학생 파업을 지지했다는...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  question            id  \\\n",
       "0                    유령'은 어느 행성에서 지구로 왔는가?  mrc-1-000653   \n",
       "1          용병회사의 경기가 좋아진 것은 무엇이 끝난 이후부터인가?  mrc-1-001113   \n",
       "2  돌푸스에게 불특정 기간동안 하원이 잠시 쉬는 것을 건의 받았던 인물은?  mrc-0-002191   \n",
       "3     마오리언어와 영어, 뉴질랜드 수화를 공식 언어로 사용하는 나라는?  mrc-0-003951   \n",
       "4               디엔비엔푸 전투에서 보응우옌잡이 상대한 국가는?  mrc-1-001272   \n",
       "\n",
       "                                             context  \n",
       "0  목성의 대기에서 보이는 줄무늬는 적도와 평행하면서 행성을 둘러싸는 대(zone)와 ...  \n",
       "1  냉전 종식 이후 전 세계적으로 소규모의 끊임없는 국지 분쟁들이 생겨나고 강대국들의 ...  \n",
       "2  1933년 3월, 투표 과정의 위법성에 대한 문제제기가 불거졌다. 당시 오스트리아 ...  \n",
       "3  유럽인들의 아메리카와 오세아니아 식민지화로 인해 아메리카와 오세아니아의 문화적, 민...  \n",
       "4  1926년 학생 시절 베트남청년혁명당에 가입했고 1930년에 학생 파업을 지지했다는...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': Value(dtype='string', id=None),\n",
       " 'id': Value(dtype='string', id=None),\n",
       " 'question': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data 에 대해선 정답이 없으므로 id question context 로만 데이터셋이 구성됩니다.\n",
    "if training_args.do_predict:\n",
    "    f = Features(\n",
    "        {\n",
    "            \"context\": Value(dtype=\"string\", id=None),\n",
    "            \"id\": Value(dtype=\"string\", id=None),\n",
    "            \"question\": Value(dtype=\"string\", id=None),\n",
    "        }\n",
    "    )\n",
    "elif training_args.do_eval:\n",
    "    f = Features(\n",
    "        {\n",
    "            \"answers\": Sequence(\n",
    "                feature={\n",
    "                    \"text\": Value(dtype=\"string\", id=None),\n",
    "                    \"answer_start\": Value(dtype=\"int32\", id=None),\n",
    "                },\n",
    "                length=-1,\n",
    "                id=None,\n",
    "            ),\n",
    "            \"context\": Value(dtype=\"string\", id=None),\n",
    "            \"id\": Value(dtype=\"string\", id=None),\n",
    "            \"question\": Value(dtype=\"string\", id=None),\n",
    "        }\n",
    "    )\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['context', 'id', 'question'],\n",
       "        num_rows: 600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_datasets = DatasetDict({\"validation\": Dataset.from_pandas(df, features=f)})\n",
    "test_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval(SentTran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build passage embedding\n",
      "Embedding pickle saved.\n"
     ]
    }
   ],
   "source": [
    "from sent_retrieval import STRetrieval\n",
    "\n",
    "retriever = STRetrieval()\n",
    "retriever.get_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[query exhaustive search] done in 1.822 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dense retrieval: 100%|██████████| 600/600 [00:02<00:00, 276.08it/s]\n"
     ]
    }
   ],
   "source": [
    "df = retriever.retrieve(test_datasets[\"validation\"], topk=data_args.top_k_retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': Value(dtype='string', id=None),\n",
       " 'id': Value(dtype='string', id=None),\n",
       " 'question': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data 에 대해선 정답이 없으므로 id question context 로만 데이터셋이 구성됩니다.\n",
    "if training_args.do_predict:\n",
    "    f = Features(\n",
    "        {\n",
    "            \"context\": Value(dtype=\"string\", id=None),\n",
    "            \"id\": Value(dtype=\"string\", id=None),\n",
    "            \"question\": Value(dtype=\"string\", id=None),\n",
    "        }\n",
    "    )\n",
    "elif training_args.do_eval:\n",
    "    f = Features(\n",
    "        {\n",
    "            \"answers\": Sequence(\n",
    "                feature={\n",
    "                    \"text\": Value(dtype=\"string\", id=None),\n",
    "                    \"answer_start\": Value(dtype=\"int32\", id=None),\n",
    "                },\n",
    "                length=-1,\n",
    "                id=None,\n",
    "            ),\n",
    "            \"context\": Value(dtype=\"string\", id=None),\n",
    "            \"id\": Value(dtype=\"string\", id=None),\n",
    "            \"question\": Value(dtype=\"string\", id=None),\n",
    "        }\n",
    "    )\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['context', 'id', 'question'],\n",
       "        num_rows: 600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_datasets = DatasetDict({\"validation\": Dataset.from_pandas(df, features=f)})\n",
    "test_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = test_datasets[\"validation\"].column_names\n",
    "\n",
    "question_column_name = \"question\" if \"question\" in column_names else column_names[0]\n",
    "context_column_name = \"context\" if \"context\" in column_names else column_names[1]\n",
    "answer_column_name = \"answers\" if \"answers\" in column_names else column_names[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding에 대한 옵션을 설정합니다.\n",
    "# (question|context) 혹은 (context|question)로 세팅 가능합니다.\n",
    "pad_on_right = tokenizer.padding_side == \"right\"\n",
    "\n",
    "# 오류가 있는지 확인합니다.\n",
    "last_checkpoint, max_seq_length = check_no_error(\n",
    "    data_args, training_args, test_datasets, tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 600/600 [00:29<00:00, 20.59 examples/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = test_datasets[\"validation\"]\n",
    "\n",
    "# Validation Feature 생성\n",
    "test_dataset = test_dataset.map(\n",
    "    prepare_validation_features,\n",
    "    batched=True,\n",
    "    num_proc=data_args.preprocessing_num_workers,\n",
    "    remove_columns=column_names,\n",
    "    load_from_cache_file=not data_args.overwrite_cache,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init trainer...\n",
      "02/22/2024 08:52:37 - WARNING - accelerate.utils.other -    Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "print(\"init trainer...\")\n",
    "# Trainer 초기화\n",
    "trainer = QuestionAnsweringTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=None,\n",
    "    eval_dataset=test_dataset,\n",
    "    eval_examples=test_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    post_process_function=post_processing_function,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2169' max='2169' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2169/2169 03:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/22/2024 08:56:47 - INFO - utils_qa -    Post-processing 600 example predictions split into 17347 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [01:17<00:00,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/22/2024 08:58:05 - INFO - utils_qa -    Saving predictions to ./outputs/test_dataset3/predictions.json.\n",
      "02/22/2024 08:58:05 - INFO - utils_qa -    Saving nbest_preds to ./outputs/test_dataset3/nbest_predictions.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No metric can be presented because there is no correct answer given. Job done!\n"
     ]
    }
   ],
   "source": [
    "#### eval dataset & eval example - predictions.json 생성됨\n",
    "predictions = trainer.predict(\n",
    "    test_dataset=test_dataset, test_examples=test_datasets[\"validation\"]\n",
    ")\n",
    "\n",
    "# predictions.json 은 postprocess_qa_predictions() 호출시 이미 저장됩니다.\n",
    "print(\n",
    "    \"No metric can be presented because there is no correct answer given. Job done!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PUSH TO HUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_REPO = 'klue-roberta-large-korquad_v1_qa'\n",
    "API_KEY = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /tmp/tmpthjcymnr/config.json\n",
      "Model weights saved in /tmp/tmpthjcymnr/pytorch_model.bin\n",
      "Uploading the following files to CurtisJeon/klue-roberta-large-korquad_v1_qa: pytorch_model.bin,config.json\n",
      "pytorch_model.bin: 100%|██████████| 1.34G/1.34G [00:56<00:00, 23.9MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/CurtisJeon/klue-roberta-large-korquad_v1_qa/commit/1cdbdc888287e1549931bcc40f6f4fe68ecb8d7b', commit_message='Upload RobertaForQuestionAnswering', commit_description='', oid='1cdbdc888287e1549931bcc40f6f4fe68ecb8d7b', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\n",
    "    MODEL_SAVE_REPO , \n",
    "    use_temp_dir=True, \n",
    "    use_auth_token=API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /tmp/tmpixan8nqw/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/tmpixan8nqw/special_tokens_map.json\n",
      "Uploading the following files to CurtisJeon/klue-roberta-large-korquad_v1_qa: tokenizer_config.json,vocab.txt,tokenizer.json,special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/CurtisJeon/klue-roberta-large-korquad_v1_qa/commit/01447181b4ff69e793b439604ad8797725205899', commit_message='Upload tokenizer', commit_description='', oid='01447181b4ff69e793b439604ad8797725205899', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(\n",
    "    MODEL_SAVE_REPO, \n",
    "    use_temp_dir=True, \n",
    "    use_auth_token=API_KEY\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
