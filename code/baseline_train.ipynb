{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "from typing import NoReturn\n",
    "from tqdm import tqdm\n",
    "\n",
    "from arguments import DataTrainingArguments, ModelArguments\n",
    "from datasets import DatasetDict, load_from_disk, load_metric, load_dataset\n",
    "from trainer_qa import QuestionAnsweringTrainer\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    "    EarlyStoppingCallback,\n",
    ")\n",
    "from utils_qa import check_no_error, postprocess_qa_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_DISABLED'] = 'false'\n",
    "os.environ['WANDB_PROJECT'] = 'level2-MRC'\n",
    "os.environ['WANDB_ENTITY'] = 'm2f'\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'JHW_JUPYTER_SERVER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 28\n",
    "deterministic = False\n",
    "\n",
    "random.seed(seed) # python random seed ê³ ì •\n",
    "np.random.seed(seed) # numpy random seed ê³ ì •\n",
    "torch.manual_seed(seed) # torch random seed ê³ ì •\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "if deterministic: # cudnn random seed ê³ ì • - ê³ ì • ì‹œ í•™ìŠµ ì†ë„ê°€ ëŠë ¤ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "\ttorch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = ModelArguments()\n",
    "data_args = DataTrainingArguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./models/train_dataset2',\n",
    "\tseed=seed,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "\tlogging_dir='./logs',\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=1,\n",
    "\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=1e-5,\n",
    "    lr_scheduler_type='cosine',\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=100,\n",
    "\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model='eval_exact_match',\n",
    "    greater_is_better=True,\n",
    "\n",
    "    report_to='wandb',\n",
    "    run_name='JHW_28',\n",
    "\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -    %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "\n",
    "# verbosity ì„¤ì • : Transformers loggerì˜ ì •ë³´ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤ (on main process only)\n",
    "logger.info(\"Training/evaluation parameters %s\", training_args)\n",
    "\n",
    "# ëª¨ë¸ì„ ì´ˆê¸°í™”í•˜ê¸° ì „ì— ë‚œìˆ˜ë¥¼ ê³ ì •í•©ë‹ˆë‹¤.\n",
    "set_seed(training_args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_from_disk(data_args.dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets['train'] = datasets['train'].remove_columns(['document_id','__index_level_0__'])\n",
    "datasets['validation'] = datasets['validation'].remove_columns(['document_id','__index_level_0__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 70133\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['title', 'context', 'question', 'id', 'answers'],\n",
       "        num_rows: 240\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for korquad\n",
    "# korquad = load_dataset('parquet', data_files=['../data/train_aug.parquet'])\n",
    "# datasets['train'] = korquad['train']\n",
    "# datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## only use if you want to finetune korquad\n",
    "# datasets = load_dataset('squad_kor_v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Negative Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3952/3952 [49:15<00:00,  1.34it/s]  \n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "# Train ë‚´ì˜ Random Context ì¦ê°•\n",
    "n_negative_samples = 2\n",
    "total_iteration = len(datasets['train'])\n",
    "\n",
    "for i in tqdm(range(total_iteration)):\n",
    "    temp_dict = datasets['train'][i]\n",
    "    temp_dict['answers'] = {'answer_start': [], 'text': []}\n",
    "    select_idx = np.random.choice([idx for idx in range(len(datasets['train'])) if idx != i], size=n_negative_samples, replace=False)\n",
    "    negative_datasets = datasets['train'].select(select_idx)\n",
    "    for n_context in negative_datasets['context']:\n",
    "        temp_dict['context'] = n_context\n",
    "        datasets['train'] = datasets['train'].add_item(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11856/11856 [00:01<00:00, 10857.31 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 240/240 [00:00<00:00, 8979.86 examples/s] \n"
     ]
    }
   ],
   "source": [
    "datasets.save_to_disk('../data/negativetrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_from_disk('../data/negativetrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'context', 'question', 'id', 'answers'],\n",
       "        num_rows: 11856\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['title', 'context', 'question', 'id', 'answers'],\n",
       "        num_rows: 240\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model, Tokenizer, Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args.model_name_or_path = 'CurtisJeon/klue-roberta-large-korquad_v1_qa-finetuned_42'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 765/765 [00:00<00:00, 2.96MB/s]\n",
      "tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.39k/1.39k [00:00<00:00, 548kB/s]\n",
      "vocab.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 248k/248k [00:00<00:00, 483kB/s]\n",
      "tokenizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 752k/752k [00:00<00:00, 1.12MB/s]\n",
      "special_tokens_map.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 971/971 [00:00<00:00, 2.46MB/s]\n",
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.34G/1.34G [00:58<00:00, 23.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "    model_args.config_name\n",
    "    if model_args.config_name is not None\n",
    "    else model_args.model_name_or_path,\n",
    "    cache_dir='/data/ephemeral/huggingface'\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_args.tokenizer_name\n",
    "    if model_args.tokenizer_name is not None\n",
    "    else model_args.model_name_or_path,\n",
    "    # 'use_fast' argumentë¥¼ Trueë¡œ ì„¤ì •í•  ê²½ìš° rustë¡œ êµ¬í˜„ëœ tokenizerë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    # Falseë¡œ ì„¤ì •í•  ê²½ìš° pythonìœ¼ë¡œ êµ¬í˜„ëœ tokenizerë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©°,\n",
    "    # rust versionì´ ë¹„êµì  ì†ë„ê°€ ë¹ ë¦…ë‹ˆë‹¤.\n",
    "    use_fast=True,\n",
    "    cache_dir='/data/ephemeral/huggingface'\n",
    ")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n",
    "    config=config,\n",
    "    cache_dir='/data/ephemeral/huggingface'\n",
    ")\n",
    "\n",
    "## token_type_ids ë¥¼ ì“°ëŠ”ì§€ ì•ˆì“°ëŠ”ì§€\n",
    "use_token_type_ids = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:821: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.34G/1.34G [00:55<00:00, 24.0MB/s]\n",
      "README.md: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.18k/5.18k [00:00<00:00, 9.13MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/CurtisJeon/klue-roberta-large-korquad_v1_qa-finetuned/commit/60fea41d546df062d8e98c20e2a66864d7e08558', commit_message='Upload tokenizer', commit_description='', oid='60fea41d546df062d8e98c20e2a66864d7e08558', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For Hub Upload\n",
    "MODEL_SAVE_REPO = 'klue-roberta-large-korquad_v1_qa-finetuned'\n",
    "API_KEY = ''\n",
    "\n",
    "# model.push_to_hub(\n",
    "#     MODEL_SAVE_REPO , \n",
    "#     use_temp_dir=True, \n",
    "#     use_auth_token=API_KEY\n",
    "# )\n",
    "\n",
    "# tokenizer.push_to_hub(\n",
    "#     MODEL_SAVE_REPO , \n",
    "#     use_temp_dir=True, \n",
    "#     use_auth_token=API_KEY\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRC-Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = datasets[\"train\"].column_names\n",
    "question_column_name = \"question\" if \"question\" in column_names else column_names[0]\n",
    "context_column_name = \"context\" if \"context\" in column_names else column_names[1]\n",
    "answer_column_name = \"answers\" if \"answers\" in column_names else column_names[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paddingì— ëŒ€í•œ ì˜µì…˜ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "# (question|context) í˜¹ì€ (context|question)ë¡œ ì„¸íŒ… ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "pad_on_right = tokenizer.padding_side == \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜¤ë¥˜ê°€ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "last_checkpoint, max_seq_length = check_no_error(\n",
    "    data_args, training_args, datasets, tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Train preprocessing / ì „ì²˜ë¦¬ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "def prepare_train_features(examples):\n",
    "    # truncationê³¼ padding(lengthê°€ ì§§ì„ë•Œë§Œ)ì„ í†µí•´ toknizationì„ ì§„í–‰í•˜ë©°, strideë¥¼ ì´ìš©í•˜ì—¬ overflowë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.\n",
    "    # ê° exampleë“¤ì€ ì´ì „ì˜ contextì™€ ì¡°ê¸ˆì”© ê²¹ì¹˜ê²Œë©ë‹ˆë‹¤.\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[question_column_name if pad_on_right else context_column_name],\n",
    "        examples[context_column_name if pad_on_right else question_column_name],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_seq_length,\n",
    "        stride=data_args.doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        return_token_type_ids=use_token_type_ids, # robertaëª¨ë¸ì„ ì‚¬ìš©í•  ê²½ìš° False, bertë¥¼ ì‚¬ìš©í•  ê²½ìš° Trueë¡œ í‘œê¸°í•´ì•¼í•©ë‹ˆë‹¤.\n",
    "        padding=\"max_length\" if data_args.pad_to_max_length else False,\n",
    "    )\n",
    "\n",
    "    # ê¸¸ì´ê°€ ê¸´ contextê°€ ë“±ì¥í•  ê²½ìš° truncateë¥¼ ì§„í–‰í•´ì•¼í•˜ë¯€ë¡œ, í•´ë‹¹ ë°ì´í„°ì…‹ì„ ì°¾ì„ ìˆ˜ ìˆë„ë¡ mapping ê°€ëŠ¥í•œ ê°’ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    # tokenì˜ ìºë¦­í„° ë‹¨ìœ„ positionë¥¼ ì°¾ì„ ìˆ˜ ìˆë„ë¡ offset mappingì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    # start_positionsê³¼ end_positionsì„ ì°¾ëŠ”ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "    # ë°ì´í„°ì…‹ì— \"start position\", \"enc position\" labelì„ ë¶€ì—¬í•©ë‹ˆë‹¤.\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)  # cls index\n",
    "\n",
    "        # sequence idë¥¼ ì„¤ì •í•©ë‹ˆë‹¤ (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "        # í•˜ë‚˜ì˜ exampleì´ ì—¬ëŸ¬ê°œì˜ spanì„ ê°€ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples[answer_column_name][sample_index]\n",
    "\n",
    "        # answerê°€ ì—†ì„ ê²½ìš° cls_indexë¥¼ answerë¡œ ì„¤ì •í•©ë‹ˆë‹¤(== exampleì—ì„œ ì •ë‹µì´ ì—†ëŠ” ê²½ìš° ì¡´ì¬í•  ìˆ˜ ìˆìŒ).\n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            # textì—ì„œ ì •ë‹µì˜ Start/end character index\n",
    "            start_char = answers[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "            # textì—ì„œ current spanì˜ Start token index\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
    "                token_start_index += 1\n",
    "\n",
    "            # textì—ì„œ current spanì˜ End token index\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
    "                token_end_index -= 1\n",
    "\n",
    "            # ì •ë‹µì´ spanì„ ë²—ì–´ë‚¬ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤(ì •ë‹µì´ ì—†ëŠ” ê²½ìš° CLS indexë¡œ labelë˜ì–´ìˆìŒ).\n",
    "            if not (\n",
    "                offsets[token_start_index][0] <= start_char\n",
    "                and offsets[token_end_index][1] >= end_char\n",
    "            ):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                # token_start_index ë° token_end_indexë¥¼ answerì˜ ëìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.\n",
    "                # Note: answerê°€ ë§ˆì§€ë§‰ ë‹¨ì–´ì¸ ê²½ìš° last offsetì„ ë”°ë¼ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤(edge case).\n",
    "                while (\n",
    "                    token_start_index < len(offsets)\n",
    "                    and offsets[token_start_index][0] <= start_char\n",
    "                ):\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_examples\n",
    "\n",
    "# Validation preprocessing\n",
    "def prepare_validation_features(examples):\n",
    "    # truncationê³¼ padding(lengthê°€ ì§§ì„ë•Œë§Œ)ì„ í†µí•´ toknizationì„ ì§„í–‰í•˜ë©°, strideë¥¼ ì´ìš©í•˜ì—¬ overflowë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.\n",
    "    # ê° exampleë“¤ì€ ì´ì „ì˜ contextì™€ ì¡°ê¸ˆì”© ê²¹ì¹˜ê²Œë©ë‹ˆë‹¤.\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[question_column_name if pad_on_right else context_column_name],\n",
    "        examples[context_column_name if pad_on_right else question_column_name],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_seq_length,\n",
    "        stride=data_args.doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        return_token_type_ids=use_token_type_ids, # robertaëª¨ë¸ì„ ì‚¬ìš©í•  ê²½ìš° False, bertë¥¼ ì‚¬ìš©í•  ê²½ìš° Trueë¡œ í‘œê¸°í•´ì•¼í•©ë‹ˆë‹¤.\n",
    "        padding=\"max_length\" if data_args.pad_to_max_length else False,\n",
    "    )\n",
    "\n",
    "    # ê¸¸ì´ê°€ ê¸´ contextê°€ ë“±ì¥í•  ê²½ìš° truncateë¥¼ ì§„í–‰í•´ì•¼í•˜ë¯€ë¡œ, í•´ë‹¹ ë°ì´í„°ì…‹ì„ ì°¾ì„ ìˆ˜ ìˆë„ë¡ mapping ê°€ëŠ¥í•œ ê°’ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    # evaluationì„ ìœ„í•´, predictionì„ contextì˜ substringìœ¼ë¡œ ë³€í™˜í•´ì•¼í•©ë‹ˆë‹¤.\n",
    "    # corresponding example_idë¥¼ ìœ ì§€í•˜ê³  offset mappingsì„ ì €ì¥í•´ì•¼í•©ë‹ˆë‹¤.\n",
    "    tokenized_examples[\"example_id\"] = []\n",
    "\n",
    "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
    "        # sequence idë¥¼ ì„¤ì •í•©ë‹ˆë‹¤ (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        context_index = 1 if pad_on_right else 0\n",
    "\n",
    "        # í•˜ë‚˜ì˜ exampleì´ ì—¬ëŸ¬ê°œì˜ spanì„ ê°€ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "        sample_index = sample_mapping[i]\n",
    "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
    "\n",
    "        # Set to None the offset_mappingì„ Noneìœ¼ë¡œ ì„¤ì •í•´ì„œ token positionì´ contextì˜ ì¼ë¶€ì¸ì§€ ì‰½ê²Œ íŒë³„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "        tokenized_examples[\"offset_mapping\"][i] = [\n",
    "            (o if sequence_ids[k] == context_index else None)\n",
    "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
    "        ]\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3952/3952 [00:05<00:00, 758.11 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 240/240 [00:00<00:00, 548.35 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets[\"train\"]\n",
    "\n",
    "# datasetì—ì„œ train featureë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "train_dataset = train_dataset.map(\n",
    "    prepare_train_features,\n",
    "    batched=True,\n",
    "    num_proc=data_args.preprocessing_num_workers,\n",
    "    remove_columns=column_names,\n",
    "    load_from_cache_file=not data_args.overwrite_cache,\n",
    ")\n",
    "\n",
    "eval_dataset = datasets[\"validation\"]\n",
    "\n",
    "# Validation Feature ìƒì„±\n",
    "eval_dataset = eval_dataset.map(\n",
    "    prepare_validation_features,\n",
    "    batched=True,\n",
    "    num_proc=data_args.preprocessing_num_workers,\n",
    "    remove_columns=column_names,\n",
    "    load_from_cache_file=not data_args.overwrite_cache,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer, pad_to_multiple_of=8 if training_args.fp16 else None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRC-Postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing:\n",
    "def post_processing_function(examples, features, predictions, training_args):\n",
    "    # Post-processing: start logitsê³¼ end logitsì„ original contextì˜ ì •ë‹µê³¼ matchì‹œí‚µë‹ˆë‹¤.\n",
    "    predictions = postprocess_qa_predictions(\n",
    "        examples=examples,\n",
    "        features=features,\n",
    "        predictions=predictions,\n",
    "        max_answer_length=data_args.max_answer_length,\n",
    "        output_dir=training_args.output_dir,\n",
    "    )\n",
    "    # Metricì„ êµ¬í•  ìˆ˜ ìˆë„ë¡ Formatì„ ë§ì¶°ì¤ë‹ˆë‹¤.\n",
    "    formatted_predictions = [\n",
    "        {\"id\": k, \"prediction_text\": v} for k, v in predictions.items()\n",
    "    ]\n",
    "    if training_args.do_predict:\n",
    "        return formatted_predictions\n",
    "\n",
    "    elif training_args.do_eval:\n",
    "        references = [\n",
    "            {\"id\": ex[\"id\"], \"answers\": ex[answer_column_name]}\n",
    "            for ex in datasets[\"validation\"]\n",
    "        ]\n",
    "        return EvalPrediction(\n",
    "            predictions=formatted_predictions, label_ids=references\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_972700/212718684.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ğŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"squad\")\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"squad\")\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    return metric.compute(predictions=p.predictions, references=p.label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find JHW_JUPYTER_SERVER.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgusdnr122997\u001b[0m (\u001b[33mm2af\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /data/ephemeral/home/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStoppingCallback(\n",
    "     early_stopping_patience=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/22/2024 07:52:07 - WARNING - accelerate.utils.other -    Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# Trainer ì´ˆê¸°í™”\n",
    "trainer = QuestionAnsweringTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset if training_args.do_train else None,\n",
    "    eval_dataset=eval_dataset if training_args.do_eval else None,\n",
    "    eval_examples=datasets[\"validation\"] if training_args.do_eval else None,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    post_process_function=post_processing_function,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgusdnr122997\u001b[0m (\u001b[33mm2f\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/level2-mrc/code/wandb/run-20240222_074916-eynu2cpd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/m2f/level2-MRC/runs/eynu2cpd' target=\"_blank\">JHW_korquad_finetuned_2</a></strong> to <a href='https://wandb.ai/m2f/level2-MRC' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/m2f/level2-MRC' target=\"_blank\">https://wandb.ai/m2f/level2-MRC</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/m2f/level2-MRC/runs/eynu2cpd' target=\"_blank\">https://wandb.ai/m2f/level2-MRC/runs/eynu2cpd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='5430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  32/5430 00:38 < 1:54:57, 0.78 it/s, Epoch 0.06/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training\n",
    "if training_args.do_train:\n",
    "    if last_checkpoint is not None:\n",
    "        checkpoint = last_checkpoint\n",
    "    elif os.path.isdir(model_args.model_name_or_path):\n",
    "        checkpoint = model_args.model_name_or_path\n",
    "    else:\n",
    "        checkpoint = None\n",
    "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
    "    trainer.save_model()  # Saves the tokenizer too for easy upload\n",
    "\n",
    "    metrics = train_result.metrics\n",
    "    metrics[\"train_samples\"] = len(train_dataset)\n",
    "\n",
    "    trainer.log_metrics(\"train\", metrics)\n",
    "    trainer.save_metrics(\"train\", metrics)\n",
    "    trainer.save_state()\n",
    "\n",
    "    output_train_file = os.path.join(training_args.output_dir, \"train_results.txt\")\n",
    "\n",
    "    with open(output_train_file, \"w\") as writer:\n",
    "        logger.info(\"***** Train results *****\")\n",
    "        for key, value in sorted(train_result.metrics.items()):\n",
    "            logger.info(f\"  {key} = {value}\")\n",
    "            writer.write(f\"{key} = {value}\\n\")\n",
    "\n",
    "    # State ì €ì¥\n",
    "    trainer.state.save_to_json(\n",
    "        os.path.join(training_args.output_dir, \"trainer_state.json\")\n",
    "    )\n",
    "\n",
    "# Evaluation\n",
    "if training_args.do_eval:\n",
    "    logger.info(\"*** Evaluate ***\")\n",
    "    metrics = trainer.evaluate()\n",
    "\n",
    "    metrics[\"eval_samples\"] = len(eval_dataset)\n",
    "\n",
    "    trainer.log_metrics(\"eval\", metrics)\n",
    "    trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/exact_match</td><td>â–â–ƒâ–†â–ˆâ–†â–†â–…â–ˆ</td></tr><tr><td>eval/f1</td><td>â–â–‚â–‡â–ˆâ–†â–…â–†â–ˆ</td></tr><tr><td>train/epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/learning_rate</td><td>â–â–‚â–ƒâ–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡</td></tr><tr><td>train/loss</td><td>â–„â–ˆâ–‡â–…â–ƒâ–…â–†â–†â–†â–†â–„â–‚â–‚â–‡â–„â–„â–„â–‚â–‡â–†â–…â–‚â–„â–‚â–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–â–…â–â–„â–‚â–‚â–†â–ƒâ–ƒâ–ƒ</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/exact_match</td><td>70.83333</td></tr><tr><td>eval/f1</td><td>80.93161</td></tr><tr><td>train/epoch</td><td>1.94</td></tr><tr><td>train/global_step</td><td>700</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.1296</td></tr><tr><td>train/total_flos</td><td>2.071736340364339e+16</td></tr><tr><td>train/train_loss</td><td>0.30219</td></tr><tr><td>train/train_runtime</td><td>1038.4126</td></tr><tr><td>train/train_samples_per_second</td><td>110.977</td></tr><tr><td>train/train_steps_per_second</td><td>3.467</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">JHW_korquad_finetuned_2</strong> at: <a href='https://wandb.ai/m2f/level2-MRC/runs/pylimvbn' target=\"_blank\">https://wandb.ai/m2f/level2-MRC/runs/pylimvbn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240221_132049-pylimvbn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, List, NoReturn, Tuple\n",
    "from datasets import (\n",
    "    Dataset,\n",
    "    DatasetDict,\n",
    "    Features,\n",
    "    Sequence,\n",
    "    Value,\n",
    "    load_from_disk,\n",
    "    load_metric,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = ModelArguments(\n",
    "    model_name_or_path='./models/train_dataset/',\n",
    ")\n",
    "data_args = DataTrainingArguments(\n",
    "    dataset_name='../data/test_dataset/',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./outputs/test_dataset3/',\n",
    "\tseed=seed,\n",
    "\n",
    "    do_train=True,\n",
    "    do_predict=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'id'],\n",
       "        num_rows: 600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_datasets = load_from_disk(data_args.dataset_name)\n",
    "test_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval (Sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if True\n",
    "data_args.eval_retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of unique contexts : 55963\n",
      "Embedding pickle load.\n"
     ]
    }
   ],
   "source": [
    "from retrieval import SparseRetrieval\n",
    "from bm25 import BM25\n",
    "\n",
    "# retriever = SparseRetrieval(\n",
    "#     tokenize_fn=tokenizer.tokenize, data_path=\"../data\", context_path=\"wiki_preprocessed.json\"\n",
    "# )\n",
    "passage_tokenizer = AutoTokenizer.from_pretrained('monologg/koelectra-base-v3-finetuned-korquad', cache_dir='/data/ephemeral/huggingface')\n",
    "\n",
    "retriever = BM25(\n",
    "    tokenize_fn=passage_tokenizer.tokenize, data_path=\"../data\", context_path=\"wiki_preprocessed_v2.json\"\n",
    ")\n",
    "retriever.get_sparse_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faiss: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [12:39<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[query exhaustive search] done in 762.739 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sparse retrieval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [00:00<00:00, 10147.63it/s]\n"
     ]
    }
   ],
   "source": [
    "print('Faiss:', data_args.use_faiss)\n",
    "if data_args.use_faiss:\n",
    "    retriever.build_faiss(num_clusters=data_args.num_clusters)\n",
    "    df = retriever.retrieve_faiss(\n",
    "        test_datasets[\"validation\"], topk=data_args.top_k_retrieval\n",
    "    )\n",
    "else:\n",
    "    df = retriever.retrieve(test_datasets[\"validation\"], topk=data_args.top_k_retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ìœ ë ¹'ì€ ì–´ëŠ í–‰ì„±ì—ì„œ ì§€êµ¬ë¡œ ì™”ëŠ”ê°€?</td>\n",
       "      <td>mrc-1-000653</td>\n",
       "      <td>ëª©ì„±ì˜ ëŒ€ê¸°ì—ì„œ ë³´ì´ëŠ” ì¤„ë¬´ëŠ¬ëŠ” ì ë„ì™€ í‰í–‰í•˜ë©´ì„œ í–‰ì„±ì„ ë‘˜ëŸ¬ì‹¸ëŠ” ëŒ€(zone)ì™€ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ìš©ë³‘íšŒì‚¬ì˜ ê²½ê¸°ê°€ ì¢‹ì•„ì§„ ê²ƒì€ ë¬´ì—‡ì´ ëë‚œ ì´í›„ë¶€í„°ì¸ê°€?</td>\n",
       "      <td>mrc-1-001113</td>\n",
       "      <td>ëƒ‰ì „ ì¢…ì‹ ì´í›„ ì „ ì„¸ê³„ì ìœ¼ë¡œ ì†Œê·œëª¨ì˜ ëŠì„ì—†ëŠ” êµ­ì§€ ë¶„ìŸë“¤ì´ ìƒê²¨ë‚˜ê³  ê°•ëŒ€êµ­ë“¤ì˜ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ëŒí‘¸ìŠ¤ì—ê²Œ ë¶ˆíŠ¹ì • ê¸°ê°„ë™ì•ˆ í•˜ì›ì´ ì ì‹œ ì‰¬ëŠ” ê²ƒì„ ê±´ì˜ ë°›ì•˜ë˜ ì¸ë¬¼ì€?</td>\n",
       "      <td>mrc-0-002191</td>\n",
       "      <td>1933ë…„ 3ì›”, íˆ¬í‘œ ê³¼ì •ì˜ ìœ„ë²•ì„±ì— ëŒ€í•œ ë¬¸ì œì œê¸°ê°€ ë¶ˆê±°ì¡Œë‹¤. ë‹¹ì‹œ ì˜¤ìŠ¤íŠ¸ë¦¬ì•„ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ë§ˆì˜¤ë¦¬ì–¸ì–´ì™€ ì˜ì–´, ë‰´ì§ˆëœë“œ ìˆ˜í™”ë¥¼ ê³µì‹ ì–¸ì–´ë¡œ ì‚¬ìš©í•˜ëŠ” ë‚˜ë¼ëŠ”?</td>\n",
       "      <td>mrc-0-003951</td>\n",
       "      <td>ìœ ëŸ½ì¸ë“¤ì˜ ì•„ë©”ë¦¬ì¹´ì™€ ì˜¤ì„¸ì•„ë‹ˆì•„ ì‹ë¯¼ì§€í™”ë¡œ ì¸í•´ ì•„ë©”ë¦¬ì¹´ì™€ ì˜¤ì„¸ì•„ë‹ˆì•„ì˜ ë¬¸í™”ì , ë¯¼...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ë””ì—”ë¹„ì—”í‘¸ ì „íˆ¬ì—ì„œ ë³´ì‘ìš°ì˜Œì¡ì´ ìƒëŒ€í•œ êµ­ê°€ëŠ”?</td>\n",
       "      <td>mrc-1-001272</td>\n",
       "      <td>1926ë…„ í•™ìƒ ì‹œì ˆ ë² íŠ¸ë‚¨ì²­ë…„í˜ëª…ë‹¹ì— ê°€ì…í–ˆê³  1930ë…„ì— í•™ìƒ íŒŒì—…ì„ ì§€ì§€í–ˆë‹¤ëŠ”...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  question            id  \\\n",
       "0                    ìœ ë ¹'ì€ ì–´ëŠ í–‰ì„±ì—ì„œ ì§€êµ¬ë¡œ ì™”ëŠ”ê°€?  mrc-1-000653   \n",
       "1          ìš©ë³‘íšŒì‚¬ì˜ ê²½ê¸°ê°€ ì¢‹ì•„ì§„ ê²ƒì€ ë¬´ì—‡ì´ ëë‚œ ì´í›„ë¶€í„°ì¸ê°€?  mrc-1-001113   \n",
       "2  ëŒí‘¸ìŠ¤ì—ê²Œ ë¶ˆíŠ¹ì • ê¸°ê°„ë™ì•ˆ í•˜ì›ì´ ì ì‹œ ì‰¬ëŠ” ê²ƒì„ ê±´ì˜ ë°›ì•˜ë˜ ì¸ë¬¼ì€?  mrc-0-002191   \n",
       "3     ë§ˆì˜¤ë¦¬ì–¸ì–´ì™€ ì˜ì–´, ë‰´ì§ˆëœë“œ ìˆ˜í™”ë¥¼ ê³µì‹ ì–¸ì–´ë¡œ ì‚¬ìš©í•˜ëŠ” ë‚˜ë¼ëŠ”?  mrc-0-003951   \n",
       "4               ë””ì—”ë¹„ì—”í‘¸ ì „íˆ¬ì—ì„œ ë³´ì‘ìš°ì˜Œì¡ì´ ìƒëŒ€í•œ êµ­ê°€ëŠ”?  mrc-1-001272   \n",
       "\n",
       "                                             context  \n",
       "0  ëª©ì„±ì˜ ëŒ€ê¸°ì—ì„œ ë³´ì´ëŠ” ì¤„ë¬´ëŠ¬ëŠ” ì ë„ì™€ í‰í–‰í•˜ë©´ì„œ í–‰ì„±ì„ ë‘˜ëŸ¬ì‹¸ëŠ” ëŒ€(zone)ì™€ ...  \n",
       "1  ëƒ‰ì „ ì¢…ì‹ ì´í›„ ì „ ì„¸ê³„ì ìœ¼ë¡œ ì†Œê·œëª¨ì˜ ëŠì„ì—†ëŠ” êµ­ì§€ ë¶„ìŸë“¤ì´ ìƒê²¨ë‚˜ê³  ê°•ëŒ€êµ­ë“¤ì˜ ...  \n",
       "2  1933ë…„ 3ì›”, íˆ¬í‘œ ê³¼ì •ì˜ ìœ„ë²•ì„±ì— ëŒ€í•œ ë¬¸ì œì œê¸°ê°€ ë¶ˆê±°ì¡Œë‹¤. ë‹¹ì‹œ ì˜¤ìŠ¤íŠ¸ë¦¬ì•„ ...  \n",
       "3  ìœ ëŸ½ì¸ë“¤ì˜ ì•„ë©”ë¦¬ì¹´ì™€ ì˜¤ì„¸ì•„ë‹ˆì•„ ì‹ë¯¼ì§€í™”ë¡œ ì¸í•´ ì•„ë©”ë¦¬ì¹´ì™€ ì˜¤ì„¸ì•„ë‹ˆì•„ì˜ ë¬¸í™”ì , ë¯¼...  \n",
       "4  1926ë…„ í•™ìƒ ì‹œì ˆ ë² íŠ¸ë‚¨ì²­ë…„í˜ëª…ë‹¹ì— ê°€ì…í–ˆê³  1930ë…„ì— í•™ìƒ íŒŒì—…ì„ ì§€ì§€í–ˆë‹¤ëŠ”...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/bm25_k25_v2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': Value(dtype='string', id=None),\n",
       " 'id': Value(dtype='string', id=None),\n",
       " 'question': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data ì— ëŒ€í•´ì„  ì •ë‹µì´ ì—†ìœ¼ë¯€ë¡œ id question context ë¡œë§Œ ë°ì´í„°ì…‹ì´ êµ¬ì„±ë©ë‹ˆë‹¤.\n",
    "if training_args.do_predict:\n",
    "    f = Features(\n",
    "        {\n",
    "            \"context\": Value(dtype=\"string\", id=None),\n",
    "            \"id\": Value(dtype=\"string\", id=None),\n",
    "            \"question\": Value(dtype=\"string\", id=None),\n",
    "        }\n",
    "    )\n",
    "elif training_args.do_eval:\n",
    "    f = Features(\n",
    "        {\n",
    "            \"answers\": Sequence(\n",
    "                feature={\n",
    "                    \"text\": Value(dtype=\"string\", id=None),\n",
    "                    \"answer_start\": Value(dtype=\"int32\", id=None),\n",
    "                },\n",
    "                length=-1,\n",
    "                id=None,\n",
    "            ),\n",
    "            \"context\": Value(dtype=\"string\", id=None),\n",
    "            \"id\": Value(dtype=\"string\", id=None),\n",
    "            \"question\": Value(dtype=\"string\", id=None),\n",
    "        }\n",
    "    )\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['context', 'id', 'question'],\n",
       "        num_rows: 600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_datasets = DatasetDict({\"validation\": Dataset.from_pandas(df, features=f)})\n",
    "test_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval(DPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dpr import DenseRetrieval\n",
    "from transformers import TrainingArguments, AutoTokenizer\n",
    "from inference import *\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"dense_retrieval\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "train_dataset = datasets['train']\n",
    "cache_dir = '/data/ephemeral/huggingface'\n",
    "\n",
    "p_encoder_path = '/data/ephemeral/huggingface/p_encoder_bert'\n",
    "q_encoder_path = '/data/ephemeral/huggingface/q_encoder_bert'\n",
    "ep_tokenizer = AutoTokenizer.from_pretrained('klue/bert-base', cache_dir=cache_dir)\n",
    "p_encoder = BertEncoder.from_pretrained(p_encoder_path, cache_dir=cache_dir).to(args.device)\n",
    "q_encoder = BertEncoder.from_pretrained(q_encoder_path, cache_dir=cache_dir).to(args.device)\n",
    "\n",
    "retriever = DenseRetrieval(\n",
    "    args=args,\n",
    "    dataset=train_dataset,\n",
    "    num_neg=2,\n",
    "    tokenizer=ep_tokenizer,\n",
    "    p_encoder=p_encoder,\n",
    "    q_encoder=q_encoder,\n",
    "    do_train=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DenseRetrieval' object has no attribute 'do_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_train\u001b[49m:\n\u001b[1;32m      2\u001b[0m     retriever\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DenseRetrieval' object has no attribute 'do_train'"
     ]
    }
   ],
   "source": [
    "if retriever.do_train:\n",
    "    retriever.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding pickle load.\n"
     ]
    }
   ],
   "source": [
    "retriever.get_dense_embeddings('../data/dense.bin', corpus_path=\"../data/wiki_preprocessed_v2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [00:09<00:00, 60.70it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [00:02<00:00, 257.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[query exhaustive search] done in 12.616 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dense retrieval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [00:03<00:00, 163.50it/s]\n"
     ]
    }
   ],
   "source": [
    "df = retriever.retrieve(test_datasets[\"validation\"], topk=data_args.top_k_retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Features(\n",
    "    {\n",
    "        \"context\": Value(dtype=\"string\", id=None),\n",
    "        \"id\": Value(dtype=\"string\", id=None),\n",
    "        \"question\": Value(dtype=\"string\", id=None),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datasets = DatasetDict({\"validation\": Dataset.from_pandas(df, features=f)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['context', 'id', 'question'],\n",
       "        num_rows: 600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval(BM25 + DPR)\n",
    "- ver2 : add SentTran Retrieval -> Remove (Low Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of unique contexts : 55963\n",
      "Embedding pickle load.\n",
      "Embedding pickle load.\n"
     ]
    }
   ],
   "source": [
    "from custom_retriever import CustomRetriever\n",
    "\n",
    "p_encoder_path = 'CurtisJeon/klue-bert-base-context'\n",
    "q_encoder_path = 'CurtisJeon/klue-bert-base-question'\n",
    "\n",
    "retriever = CustomRetriever(\n",
    "    p_encoder_path=p_encoder_path, q_encoder_path=q_encoder_path, weights=(0.5, 0.5) # (bm25, dpr)\n",
    ")\n",
    "# retriever.dpr_tokenizer = AutoTokenizer.from_pretrained('kykim/bert-kor-base', cache_dir='/data/ephemeral/huggingface')\n",
    "retriever.get_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 Result pickle load.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [00:11<00:00, 52.32it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [00:07<00:00, 79.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[query exhaustive search] done in 91.225 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sparse retrieval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [00:00<00:00, 3458.59it/s]\n"
     ]
    }
   ],
   "source": [
    "df = retriever.retrieve(test_datasets[\"validation\"], topk=data_args.top_k_retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/bm25_dpr(5_5)_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ìœ ë ¹'ì€ ì–´ëŠ í–‰ì„±ì—ì„œ ì§€êµ¬ë¡œ ì™”ëŠ”ê°€?</td>\n",
       "      <td>mrc-1-000653</td>\n",
       "      <td>ëª©ì„±ì˜ ëŒ€ê¸°ì—ì„œ ë³´ì´ëŠ” ì¤„ë¬´ëŠ¬ëŠ” ì ë„ì™€ í‰í–‰í•˜ë©´ì„œ í–‰ì„±ì„ ë‘˜ëŸ¬ì‹¸ëŠ” ëŒ€(zone)ì™€ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ìš©ë³‘íšŒì‚¬ì˜ ê²½ê¸°ê°€ ì¢‹ì•„ì§„ ê²ƒì€ ë¬´ì—‡ì´ ëë‚œ ì´í›„ë¶€í„°ì¸ê°€?</td>\n",
       "      <td>mrc-1-001113</td>\n",
       "      <td>ëƒ‰ì „ ì¢…ì‹ ì´í›„ ì „ ì„¸ê³„ì ìœ¼ë¡œ ì†Œê·œëª¨ì˜ ëŠì„ì—†ëŠ” êµ­ì§€ ë¶„ìŸë“¤ì´ ìƒê²¨ë‚˜ê³  ê°•ëŒ€êµ­ë“¤ì˜ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ëŒí‘¸ìŠ¤ì—ê²Œ ë¶ˆíŠ¹ì • ê¸°ê°„ë™ì•ˆ í•˜ì›ì´ ì ì‹œ ì‰¬ëŠ” ê²ƒì„ ê±´ì˜ ë°›ì•˜ë˜ ì¸ë¬¼ì€?</td>\n",
       "      <td>mrc-0-002191</td>\n",
       "      <td>1933ë…„ 3ì›”, íˆ¬í‘œ ê³¼ì •ì˜ ìœ„ë²•ì„±ì— ëŒ€í•œ ë¬¸ì œì œê¸°ê°€ ë¶ˆê±°ì¡Œë‹¤. ë‹¹ì‹œ ì˜¤ìŠ¤íŠ¸ë¦¬ì•„ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ë§ˆì˜¤ë¦¬ì–¸ì–´ì™€ ì˜ì–´, ë‰´ì§ˆëœë“œ ìˆ˜í™”ë¥¼ ê³µì‹ ì–¸ì–´ë¡œ ì‚¬ìš©í•˜ëŠ” ë‚˜ë¼ëŠ”?</td>\n",
       "      <td>mrc-0-003951</td>\n",
       "      <td>ìœ ëŸ½ì¸ë“¤ì˜ ì•„ë©”ë¦¬ì¹´ì™€ ì˜¤ì„¸ì•„ë‹ˆì•„ ì‹ë¯¼ì§€í™”ë¡œ ì¸í•´ ì•„ë©”ë¦¬ì¹´ì™€ ì˜¤ì„¸ì•„ë‹ˆì•„ì˜ ë¬¸í™”ì , ë¯¼...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ë””ì—”ë¹„ì—”í‘¸ ì „íˆ¬ì—ì„œ ë³´ì‘ìš°ì˜Œì¡ì´ ìƒëŒ€í•œ êµ­ê°€ëŠ”?</td>\n",
       "      <td>mrc-1-001272</td>\n",
       "      <td>1926ë…„ í•™ìƒ ì‹œì ˆ ë² íŠ¸ë‚¨ì²­ë…„í˜ëª…ë‹¹ì— ê°€ì…í–ˆê³  1930ë…„ì— í•™ìƒ íŒŒì—…ì„ ì§€ì§€í–ˆë‹¤ëŠ”...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  question            id  \\\n",
       "0                    ìœ ë ¹'ì€ ì–´ëŠ í–‰ì„±ì—ì„œ ì§€êµ¬ë¡œ ì™”ëŠ”ê°€?  mrc-1-000653   \n",
       "1          ìš©ë³‘íšŒì‚¬ì˜ ê²½ê¸°ê°€ ì¢‹ì•„ì§„ ê²ƒì€ ë¬´ì—‡ì´ ëë‚œ ì´í›„ë¶€í„°ì¸ê°€?  mrc-1-001113   \n",
       "2  ëŒí‘¸ìŠ¤ì—ê²Œ ë¶ˆíŠ¹ì • ê¸°ê°„ë™ì•ˆ í•˜ì›ì´ ì ì‹œ ì‰¬ëŠ” ê²ƒì„ ê±´ì˜ ë°›ì•˜ë˜ ì¸ë¬¼ì€?  mrc-0-002191   \n",
       "3     ë§ˆì˜¤ë¦¬ì–¸ì–´ì™€ ì˜ì–´, ë‰´ì§ˆëœë“œ ìˆ˜í™”ë¥¼ ê³µì‹ ì–¸ì–´ë¡œ ì‚¬ìš©í•˜ëŠ” ë‚˜ë¼ëŠ”?  mrc-0-003951   \n",
       "4               ë””ì—”ë¹„ì—”í‘¸ ì „íˆ¬ì—ì„œ ë³´ì‘ìš°ì˜Œì¡ì´ ìƒëŒ€í•œ êµ­ê°€ëŠ”?  mrc-1-001272   \n",
       "\n",
       "                                             context  \n",
       "0  ëª©ì„±ì˜ ëŒ€ê¸°ì—ì„œ ë³´ì´ëŠ” ì¤„ë¬´ëŠ¬ëŠ” ì ë„ì™€ í‰í–‰í•˜ë©´ì„œ í–‰ì„±ì„ ë‘˜ëŸ¬ì‹¸ëŠ” ëŒ€(zone)ì™€ ...  \n",
       "1  ëƒ‰ì „ ì¢…ì‹ ì´í›„ ì „ ì„¸ê³„ì ìœ¼ë¡œ ì†Œê·œëª¨ì˜ ëŠì„ì—†ëŠ” êµ­ì§€ ë¶„ìŸë“¤ì´ ìƒê²¨ë‚˜ê³  ê°•ëŒ€êµ­ë“¤ì˜ ...  \n",
       "2  1933ë…„ 3ì›”, íˆ¬í‘œ ê³¼ì •ì˜ ìœ„ë²•ì„±ì— ëŒ€í•œ ë¬¸ì œì œê¸°ê°€ ë¶ˆê±°ì¡Œë‹¤. ë‹¹ì‹œ ì˜¤ìŠ¤íŠ¸ë¦¬ì•„ ...  \n",
       "3  ìœ ëŸ½ì¸ë“¤ì˜ ì•„ë©”ë¦¬ì¹´ì™€ ì˜¤ì„¸ì•„ë‹ˆì•„ ì‹ë¯¼ì§€í™”ë¡œ ì¸í•´ ì•„ë©”ë¦¬ì¹´ì™€ ì˜¤ì„¸ì•„ë‹ˆì•„ì˜ ë¬¸í™”ì , ë¯¼...  \n",
       "4  1926ë…„ í•™ìƒ ì‹œì ˆ ë² íŠ¸ë‚¨ì²­ë…„í˜ëª…ë‹¹ì— ê°€ì…í–ˆê³  1930ë…„ì— í•™ìƒ íŒŒì—…ì„ ì§€ì§€í–ˆë‹¤ëŠ”...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': Value(dtype='string', id=None),\n",
       " 'id': Value(dtype='string', id=None),\n",
       " 'question': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data ì— ëŒ€í•´ì„  ì •ë‹µì´ ì—†ìœ¼ë¯€ë¡œ id question context ë¡œë§Œ ë°ì´í„°ì…‹ì´ êµ¬ì„±ë©ë‹ˆë‹¤.\n",
    "if training_args.do_predict:\n",
    "    f = Features(\n",
    "        {\n",
    "            \"context\": Value(dtype=\"string\", id=None),\n",
    "            \"id\": Value(dtype=\"string\", id=None),\n",
    "            \"question\": Value(dtype=\"string\", id=None),\n",
    "        }\n",
    "    )\n",
    "elif training_args.do_eval:\n",
    "    f = Features(\n",
    "        {\n",
    "            \"answers\": Sequence(\n",
    "                feature={\n",
    "                    \"text\": Value(dtype=\"string\", id=None),\n",
    "                    \"answer_start\": Value(dtype=\"int32\", id=None),\n",
    "                },\n",
    "                length=-1,\n",
    "                id=None,\n",
    "            ),\n",
    "            \"context\": Value(dtype=\"string\", id=None),\n",
    "            \"id\": Value(dtype=\"string\", id=None),\n",
    "            \"question\": Value(dtype=\"string\", id=None),\n",
    "        }\n",
    "    )\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['context', 'id', 'question'],\n",
       "        num_rows: 600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_datasets = DatasetDict({\"validation\": Dataset.from_pandas(df, features=f)})\n",
    "test_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval(SentTran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build passage embedding\n",
      "Embedding pickle saved.\n"
     ]
    }
   ],
   "source": [
    "from sent_retrieval import STRetrieval\n",
    "\n",
    "retriever = STRetrieval()\n",
    "retriever.get_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[query exhaustive search] done in 1.822 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dense retrieval: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [00:02<00:00, 276.08it/s]\n"
     ]
    }
   ],
   "source": [
    "df = retriever.retrieve(test_datasets[\"validation\"], topk=data_args.top_k_retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': Value(dtype='string', id=None),\n",
       " 'id': Value(dtype='string', id=None),\n",
       " 'question': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data ì— ëŒ€í•´ì„  ì •ë‹µì´ ì—†ìœ¼ë¯€ë¡œ id question context ë¡œë§Œ ë°ì´í„°ì…‹ì´ êµ¬ì„±ë©ë‹ˆë‹¤.\n",
    "if training_args.do_predict:\n",
    "    f = Features(\n",
    "        {\n",
    "            \"context\": Value(dtype=\"string\", id=None),\n",
    "            \"id\": Value(dtype=\"string\", id=None),\n",
    "            \"question\": Value(dtype=\"string\", id=None),\n",
    "        }\n",
    "    )\n",
    "elif training_args.do_eval:\n",
    "    f = Features(\n",
    "        {\n",
    "            \"answers\": Sequence(\n",
    "                feature={\n",
    "                    \"text\": Value(dtype=\"string\", id=None),\n",
    "                    \"answer_start\": Value(dtype=\"int32\", id=None),\n",
    "                },\n",
    "                length=-1,\n",
    "                id=None,\n",
    "            ),\n",
    "            \"context\": Value(dtype=\"string\", id=None),\n",
    "            \"id\": Value(dtype=\"string\", id=None),\n",
    "            \"question\": Value(dtype=\"string\", id=None),\n",
    "        }\n",
    "    )\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['context', 'id', 'question'],\n",
       "        num_rows: 600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_datasets = DatasetDict({\"validation\": Dataset.from_pandas(df, features=f)})\n",
    "test_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = test_datasets[\"validation\"].column_names\n",
    "\n",
    "question_column_name = \"question\" if \"question\" in column_names else column_names[0]\n",
    "context_column_name = \"context\" if \"context\" in column_names else column_names[1]\n",
    "answer_column_name = \"answers\" if \"answers\" in column_names else column_names[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paddingì— ëŒ€í•œ ì˜µì…˜ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "# (question|context) í˜¹ì€ (context|question)ë¡œ ì„¸íŒ… ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "pad_on_right = tokenizer.padding_side == \"right\"\n",
    "\n",
    "# ì˜¤ë¥˜ê°€ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "last_checkpoint, max_seq_length = check_no_error(\n",
    "    data_args, training_args, test_datasets, tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [00:29<00:00, 20.59 examples/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = test_datasets[\"validation\"]\n",
    "\n",
    "# Validation Feature ìƒì„±\n",
    "test_dataset = test_dataset.map(\n",
    "    prepare_validation_features,\n",
    "    batched=True,\n",
    "    num_proc=data_args.preprocessing_num_workers,\n",
    "    remove_columns=column_names,\n",
    "    load_from_cache_file=not data_args.overwrite_cache,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init trainer...\n",
      "02/22/2024 08:52:37 - WARNING - accelerate.utils.other -    Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "print(\"init trainer...\")\n",
    "# Trainer ì´ˆê¸°í™”\n",
    "trainer = QuestionAnsweringTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=None,\n",
    "    eval_dataset=test_dataset,\n",
    "    eval_examples=test_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    post_process_function=post_processing_function,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2169' max='2169' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2169/2169 03:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/22/2024 08:56:47 - INFO - utils_qa -    Post-processing 600 example predictions split into 17347 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [01:17<00:00,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02/22/2024 08:58:05 - INFO - utils_qa -    Saving predictions to ./outputs/test_dataset3/predictions.json.\n",
      "02/22/2024 08:58:05 - INFO - utils_qa -    Saving nbest_preds to ./outputs/test_dataset3/nbest_predictions.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No metric can be presented because there is no correct answer given. Job done!\n"
     ]
    }
   ],
   "source": [
    "#### eval dataset & eval example - predictions.json ìƒì„±ë¨\n",
    "predictions = trainer.predict(\n",
    "    test_dataset=test_dataset, test_examples=test_datasets[\"validation\"]\n",
    ")\n",
    "\n",
    "# predictions.json ì€ postprocess_qa_predictions() í˜¸ì¶œì‹œ ì´ë¯¸ ì €ì¥ë©ë‹ˆë‹¤.\n",
    "print(\n",
    "    \"No metric can be presented because there is no correct answer given. Job done!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PUSH TO HUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_REPO = 'klue-roberta-large-korquad_v1_qa'\n",
    "API_KEY = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /tmp/tmpthjcymnr/config.json\n",
      "Model weights saved in /tmp/tmpthjcymnr/pytorch_model.bin\n",
      "Uploading the following files to CurtisJeon/klue-roberta-large-korquad_v1_qa: pytorch_model.bin,config.json\n",
      "pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.34G/1.34G [00:56<00:00, 23.9MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/CurtisJeon/klue-roberta-large-korquad_v1_qa/commit/1cdbdc888287e1549931bcc40f6f4fe68ecb8d7b', commit_message='Upload RobertaForQuestionAnswering', commit_description='', oid='1cdbdc888287e1549931bcc40f6f4fe68ecb8d7b', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\n",
    "    MODEL_SAVE_REPO , \n",
    "    use_temp_dir=True, \n",
    "    use_auth_token=API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /tmp/tmpixan8nqw/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/tmpixan8nqw/special_tokens_map.json\n",
      "Uploading the following files to CurtisJeon/klue-roberta-large-korquad_v1_qa: tokenizer_config.json,vocab.txt,tokenizer.json,special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/CurtisJeon/klue-roberta-large-korquad_v1_qa/commit/01447181b4ff69e793b439604ad8797725205899', commit_message='Upload tokenizer', commit_description='', oid='01447181b4ff69e793b439604ad8797725205899', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(\n",
    "    MODEL_SAVE_REPO, \n",
    "    use_temp_dir=True, \n",
    "    use_auth_token=API_KEY\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
